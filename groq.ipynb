{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-11 20:31:51 - Loaded .env file\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.memory import ChatMessageHistory, ConversationBufferMemory\n",
    "import chainlit as cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, wget\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain.embeddings.fastembed import FastEmbedEmbeddings\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printmd(string):\n",
    "\tdisplay(Markdown(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Update with your API URL if using a hosted instance of Langsmith.\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"ls__b338d581f71b48b099c981bf36b095b6\"  # Update with your API key\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "project_name = \"groq\"  # Update with your project name\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = project_name  # Optional: \"default\" is used if not set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import (\n",
    "    ChatGoogleGenerativeAI,\n",
    "    HarmBlockThreshold,\n",
    "    HarmCategory,\n",
    ")\n",
    "from dotenv import load_dotenv\n",
    "# safe ={\n",
    "# \tHarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "# \tHarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "# \tHarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "# \tHarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "# \t}\n",
    "\n",
    "# generation_config = {\n",
    "#   \"temperature\": 0.9,\n",
    "#   \"top_p\": 1,\n",
    "#   \"top_k\": 1,\n",
    "#   \"max_output_tokens\": 10000,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatGoogleGenerativeAI(model=\"gemini-1.0-pro-latest\", convert_system_message_to_human=True, generation_config=generation_config,safety_settings=safe, embeddings=OllamaEmbeddings(model=\"nomic-embed-text\"))\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.0-pro-latest\", convert_system_message_to_human=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGoogleGenerativeAI(model='gemini-1.0-pro-latest', client= genai.GenerativeModel(\n",
       "   model_name='models/gemini-1.0-pro-latest',\n",
       "   generation_config={}.\n",
       "   safety_settings={}\n",
       "), convert_system_message_to_human=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Config',\n",
       " 'InputType',\n",
       " 'OutputType',\n",
       " '__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__class_vars__',\n",
       " '__config__',\n",
       " '__custom_root_type__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__exclude_fields__',\n",
       " '__fields__',\n",
       " '__fields_set__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__get_validators__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__include_fields__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__json_encoder__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__or__',\n",
       " '__orig_bases__',\n",
       " '__parameters__',\n",
       " '__post_root_validators__',\n",
       " '__pre_root_validators__',\n",
       " '__pretty__',\n",
       " '__private_attributes__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__repr_args__',\n",
       " '__repr_name__',\n",
       " '__repr_str__',\n",
       " '__rich_repr__',\n",
       " '__ror__',\n",
       " '__schema_cache__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__signature__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__try_update_forward_refs__',\n",
       " '__validators__',\n",
       " '__weakref__',\n",
       " '_abatch_with_config',\n",
       " '_abc_impl',\n",
       " '_acall_with_config',\n",
       " '_agenerate',\n",
       " '_agenerate_with_cache',\n",
       " '_all_required_field_names',\n",
       " '_astream',\n",
       " '_atransform_stream_with_config',\n",
       " '_batch_with_config',\n",
       " '_calculate_keys',\n",
       " '_call_async',\n",
       " '_call_with_config',\n",
       " '_combine_llm_outputs',\n",
       " '_convert_input',\n",
       " '_copy_and_set_values',\n",
       " '_decompose_class',\n",
       " '_enforce_dict_if_root',\n",
       " '_generate',\n",
       " '_generate_with_cache',\n",
       " '_get_invocation_params',\n",
       " '_get_llm_string',\n",
       " '_get_value',\n",
       " '_identifying_params',\n",
       " '_init_private_attributes',\n",
       " '_is_protocol',\n",
       " '_iter',\n",
       " '_lc_kwargs',\n",
       " '_llm_type',\n",
       " '_model_family',\n",
       " '_prepare_chat',\n",
       " '_prepare_params',\n",
       " '_stream',\n",
       " '_transform_stream_with_config',\n",
       " 'abatch',\n",
       " 'agenerate',\n",
       " 'agenerate_prompt',\n",
       " 'ainvoke',\n",
       " 'apredict',\n",
       " 'apredict_messages',\n",
       " 'assign',\n",
       " 'astream',\n",
       " 'astream_events',\n",
       " 'astream_log',\n",
       " 'atransform',\n",
       " 'batch',\n",
       " 'bind',\n",
       " 'cache',\n",
       " 'call_as_llm',\n",
       " 'callback_manager',\n",
       " 'callbacks',\n",
       " 'client',\n",
       " 'client_options',\n",
       " 'config_schema',\n",
       " 'config_specs',\n",
       " 'configurable_alternatives',\n",
       " 'configurable_fields',\n",
       " 'construct',\n",
       " 'convert_system_message_to_human',\n",
       " 'copy',\n",
       " 'dict',\n",
       " 'from_orm',\n",
       " 'generate',\n",
       " 'generate_prompt',\n",
       " 'get_graph',\n",
       " 'get_input_schema',\n",
       " 'get_lc_namespace',\n",
       " 'get_name',\n",
       " 'get_num_tokens',\n",
       " 'get_num_tokens_from_messages',\n",
       " 'get_output_schema',\n",
       " 'get_prompts',\n",
       " 'get_token_ids',\n",
       " 'google_api_key',\n",
       " 'input_schema',\n",
       " 'invoke',\n",
       " 'is_lc_serializable',\n",
       " 'json',\n",
       " 'lc_attributes',\n",
       " 'lc_id',\n",
       " 'lc_secrets',\n",
       " 'map',\n",
       " 'max_output_tokens',\n",
       " 'max_retries',\n",
       " 'metadata',\n",
       " 'model',\n",
       " 'n',\n",
       " 'name',\n",
       " 'output_schema',\n",
       " 'parse_file',\n",
       " 'parse_obj',\n",
       " 'parse_raw',\n",
       " 'pick',\n",
       " 'pipe',\n",
       " 'predict',\n",
       " 'predict_messages',\n",
       " 'raise_deprecation',\n",
       " 'safety_settings',\n",
       " 'schema',\n",
       " 'schema_json',\n",
       " 'stream',\n",
       " 'tags',\n",
       " 'temperature',\n",
       " 'to_json',\n",
       " 'to_json_not_implemented',\n",
       " 'top_k',\n",
       " 'top_p',\n",
       " 'transform',\n",
       " 'transport',\n",
       " 'update_forward_refs',\n",
       " 'validate',\n",
       " 'validate_environment',\n",
       " 'verbose',\n",
       " 'with_config',\n",
       " 'with_fallbacks',\n",
       " 'with_listeners',\n",
       " 'with_retry',\n",
       " 'with_structured_output',\n",
       " 'with_types']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7\n"
     ]
    }
   ],
   "source": [
    "print(llm.temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_local = ChatOllama(model=\"mistral:instruct\")\n",
    "llm_groq = ChatGroq(\n",
    "            #groq_api_key=groq_api_key,\n",
    "            #model_name='llama2-70b-4096' \n",
    "            model_name='mixtral-8x7b-32768'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "301896"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open the_prince.txt and read the text\n",
    "with open('the_prince.txt', 'r') as file:\n",
    "    text = file.read()\t\n",
    "len(text)\n",
    "# loader = TextLoader('the_prince.txt')\n",
    "# documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader = PyPDFLoader(\"Machiavelli_The_Prince.pdf\")\n",
    "# pages = loader.load_and_split()\n",
    "\n",
    "# text = \" \".join(page.page_content for page in pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings_model = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "# embeddings_model = FastEmbedEmbeddings()\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.28 s, sys: 63.7 ms, total: 4.34 s\n",
      "Wall time: 14.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Initialize the semantic chunker with the pre-generated embeddings\n",
    "chunker = SemanticChunker(embeddings_model)\n",
    "\n",
    "# Split the text into chunks based on the embeddings\n",
    "chunks = chunker.create_documents([text])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.25 ms, sys: 0 ns, total: 9.25 ms\n",
      "Wall time: 9.08 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size=2000,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "texts = text_splitter.create_documents([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embeddings_model = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "# db = FAISS.from_documents(texts, embeddings_model)\n",
    "db = Chroma.from_documents(texts, embeddings_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How did Francesco Sforza rose to be Duke of Milan?\"\n",
    "docs = db.similarity_search(query)\n",
    "\n",
    "# print results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Concerning these two methods of rising to be a prince by ability or\n",
       "fortune, I wish to adduce two examples within our own recollection, and\n",
       "these are Francesco Sforza[2] and Cesare Borgia. Francesco, by proper\n",
       "means and with great ability, from being a private person rose to be\n",
       "Duke of Milan, and that which he had acquired with a thousand anxieties\n",
       "he kept with little trouble. On the other hand, Cesare Borgia, called\n",
       "by the people Duke Valentino, acquired his state during the ascendancy\n",
       "of his father, and on its decline he lost it, notwithstanding that he\n",
       "had taken every measure and done all that ought to be done by a wise\n",
       "and able man to fix firmly his roots in the states which the arms and\n",
       "fortunes of others had bestowed on him.\n",
       "\n",
       " [2] Francesco Sforza, born 1401, died 1466. He married Bianca Maria\n",
       " Visconti, a natural daughter of Filippo Visconti, the Duke of Milan,\n",
       " on whose death he procured his own elevation to the duchy. Machiavelli\n",
       " was the accredited agent of the Florentine Republic to Cesare Borgia\n",
       " (1478-1507) during the transactions which led up to the assassinations\n",
       " of the Orsini and Vitelli at Sinigalia, and along with his letters to\n",
       " his chiefs in Florence he has left an account, written ten years\n",
       " before _The Prince_, of the proceedings of the duke in his\n",
       " “Descritione del modo tenuto dal duca Valentino nello ammazzare\n",
       " Vitellozzo Vitelli,” etc., a translation of which is appended to the\n",
       " present work."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Alexander the Sixth, in wishing to aggrandize the duke, his son, had\n",
       "many immediate and prospective difficulties. Firstly, he did not see\n",
       "his way to make him master of any state that was not a state of the\n",
       "Church; and if he was willing to rob the Church he knew that the Duke\n",
       "of Milan and the Venetians would not consent, because Faenza and Rimini\n",
       "were already under the protection of the Venetians. Besides this, he\n",
       "saw the arms of Italy, especially those by which he might have been\n",
       "assisted, in hands that would fear the aggrandizement of the Pope,\n",
       "namely, the Orsini and the Colonnesi and their following. It behoved\n",
       "him, therefore, to upset this state of affairs and embroil the powers,\n",
       "so as to make himself securely master of part of their states. This was\n",
       "easy for him to do, because he found the Venetians, moved by other\n",
       "reasons, inclined to bring back the French into Italy; he would not\n",
       "only not oppose this, but he would render it more easy by dissolving\n",
       "the former marriage of King Louis. Therefore the king came into Italy\n",
       "with the assistance of the Venetians and the consent of Alexander. He\n",
       "was no sooner in Milan than the Pope had soldiers from him for the\n",
       "attempt on the Romagna, which yielded to him on the reputation of the\n",
       "king. The duke, therefore, having acquired the Romagna and beaten the\n",
       "Colonnesi, while wishing to hold that and to advance further, was\n",
       "hindered by two things: the one, his forces did not appear loyal to\n",
       "him, the other, the goodwill of France: that is to say, he feared that\n",
       "the forces of the Orsini, which he was using, would not stand to him,\n",
       "that not only might they hinder him from winning more, but might\n",
       "themselves seize what he had won, and that the king might also do the\n",
       "same. Of the Orsini he had a warning when, after taking Faenza and\n",
       "attacking Bologna, he saw them go very unwillingly to that attack. And\n",
       "as to the king, he learned his mind when he himself, after taking the"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Frederick, having appointed a governor in Rome to watch his Italian\n",
       "affairs, returned to Germany. All the Tuscan and Lombardian\n",
       "Ghibellines, who followed the imperial lead, had recourse to Castruccio\n",
       "for help and counsel, and all promised him the governorship of his\n",
       "country, if enabled to recover it with his assistance. Among these\n",
       "exiles were Matteo Guidi, Nardo Scolari, Lapo Uberti, Gerozzo Nardi,\n",
       "and Piero Buonaccorsi, all exiled Florentines and Ghibellines.\n",
       "Castruccio had the secret intention of becoming the master of all\n",
       "Tuscany by the aid of these men and of his own forces; and in order to\n",
       "gain greater weight in affairs, he entered into a league with Messer\n",
       "Matteo Visconti, the Prince of Milan, and organized for him the forces\n",
       "of his city and the country districts. As Lucca had five gates, he\n",
       "divided his own country districts into five parts, which he supplied\n",
       "with arms, and enrolled the men under captains and ensigns, so that he\n",
       "could quickly bring into the field twenty thousand soldiers, without\n",
       "those whom he could summon to his assistance from Pisa. While he\n",
       "surrounded himself with these forces and allies, it happened at Messer\n",
       "Matteo Visconti was attacked by the Guelphs of Piacenza, who had driven\n",
       "out the Ghibellines with the assistance of a Florentine army and the\n",
       "King Ruberto. Messer Matteo called upon Castruccio to invade the\n",
       "Florentines in their own territories, so that, being attacked at home,\n",
       "they should be compelled to draw their army out of Lombardy in order to\n",
       "defend themselves. Castruccio invaded the Valdarno, and seized\n",
       "Fucecchio and San Miniato, inflicting immense damage upon the country.\n",
       "Whereupon the Florentines recalled their army, which had scarcely\n",
       "reached Tuscany, when Castruccio was forced by other necessities to\n",
       "return to Lucca."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(3):\t\n",
    "\tprintmd(docs[i].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "docs_texts = [d.page_content for d in texts]\n",
    "\n",
    "# Calculate the number of tokens for each document\n",
    "counts = [num_tokens_from_string(d, \"cl100k_base\") for d in docs_texts]\n",
    "\n",
    "# Plotting the histogram of token counts\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(counts, bins=30, color=\"blue\", edgecolor=\"black\", alpha=0.7)\n",
    "plt.title(\"Histogram of Token Counts\")\n",
    "plt.xlabel(\"Token Count\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(axis=\"y\", alpha=0.75)\n",
    "\n",
    "# Display the histogram\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
